



import gc  # Garbage collector
import sys
import numpy as np
import pandas as pd

path_to_scripts = '../../scripts/'
sys.path.append(path_to_scripts)
from smiles_property_extractor import ChemicalInfoFromSmiles




##dataset after cleaning
db_name = '../../datasets/processed/cleaned_data_v1.csv'

##dataset wo outliers
#db_name = '../datasets/cleaned_data_v2.csv'

db = pd.read_csv(db_name)




print('Generating a new dataset of smiles, raw and transformend  solubilities ...')
db_ = db[['molindx', 'SMILES', 'Temperature', 'ExperimentalSolubilityInWater']]

db_ = db_.assign(logS=lambda x: (np.log(x['ExperimentalSolubilityInWater'])))

db_['ExperimentalSolubilityInWater'] = db_['ExperimentalSolubilityInWater'].round(3)
db_['logS'] = db_['logS'].round(5)







from joblib import Parallel, delayed

# Define a function to handle a single row
def process_row(smiles):
    return ChemicalInfoFromSmiles.get_rdkit_2dDescriptors_from_smiles(smiles)

# Use joblib to parallelize the task
print('This process might take a bit of time. Please be patient.')
df = Parallel(n_jobs=-1)(delayed(process_row)(smiles) for smiles in db_['SMILES'])

# Convert the list of results into a DataFrame
df = pd.DataFrame(df)




db = pd.concat([db_, df], axis=1)
db = db.drop(columns=['SMILES', 'ExperimentalSolubilityInWater'], axis=1)
db




#filtration 3 (for attributes)
db_filtered = db.loc[:, ~(db == 0).all()]
number_of_columns_with_zeros = db.shape[1] - db_filtered.shape[1]
print(f'{number_of_columns_with_zeros} columns are fully zero.')




#filtration 4 (for attributes)
db_ = db_filtered.dropna(axis=1)
number_of_columns_with_Nans = db_filtered.shape[1] - db_.shape[1]
print(f'{number_of_columns_with_Nans} columns are fully np.nan.')

db_




db_.to_csv('../../datasets/processed/datasetRdkitDescriptors.csv',  index=False)

#dataset wo outliers
#db_.to_csv('../../datasets/processed/datasetRdkitDescriptors_v2.csv',  index=False)




